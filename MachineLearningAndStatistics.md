Active Readings <br>
1. https://platform.openai.com/docs/overview <br>

___________________________________________________________________________  <br>

Reading 1: <br>
James, G., Witten, D., Hastie, T., Tibshirani, R., & Taylor, J. (2023). An introduction to statistical learning: With applications in python. Springer Nature. </br> 

Reading 2: <br>
Molnar, C. (2020). Interpretable machine learning. Lulu. com. <br>

Reading 3: <br>
Casella, G., & Berger, R. (2024). Statistical inference. CRC Press. <br>

Reading 4: <br>
Bishop, C. M., & Bishop, H. (2023). Deep learning: Foundations and concepts. Springer Nature. <br>

Reading 5: <br>
Chang, J. M., Zhuang, D., Samaraweera, G., & Samaraweera, G. D. (2023). Privacy-Preserving Machine Learning. Simon and Schuster. <br>

Reading 6: <br>
Thampi, A. (2022). Interpretable AI: Building explainable machine learning systems. Simon and Schuster. <br>

Reading 7: <br>
Mehta, M., Palade, V., & Chatterjee, I. (Eds.). (2023). Explainable AI: Foundations, methodologies and applications. Springer. <br>

Reading 8: <br>
Mishra, P. (2022). Practical explainable AI using python: Artificial intelligence model explanations using python-based libraries, extensions, and frameworks. Apress. <br>

Reading 9: <br>
Pan, Z., & Mishra, P. (2024). Explainable AI for Cybersecurity. Springer International Publishing AG. <br>

Reading 10: <br>
https://www.microsoft.com/en-us/research/blog/privacy-preserving-machine-learning-maintaining-confidentiality-and-preserving-trust/
https://www.microsoft.com/en-us/research/group/privacy-preserving-machine-learning-innovation/
https://www.alexandra.dk/wp-content/uploads/2020/10/Alexandra-Instituttet-whitepaper-Privacy-Preserving-Machine-Learning-A-Practical-Guide.pdf
<br>

Reading 11: <br>
Aravilli, S. R. (2024). PRIVACY-PRESERVING MACHINE LEARNING: a use-case-driven approach to develop and protecting ML pipelines from privacy and security threats. <br>

Reading 12: <br>
Mas√≠s, S. (2023). Interpretable Machine Learning with Python: Build explainable, fair, and robust high-performance models with hands-on, real-world examples. Packt Publishing Ltd. <br>

Reading 13: <br>
Richards, T. (2023). Streamlit for Data Science: Create interactive data apps in Python. Packt Publishing Ltd. <br>

Reading 14: <br>
https://aws.amazon.com/es/blogs/machine-learning/how-deloitte-italy-built-a-digital-payments-fraud-detection-solution-using-quantum-machine-learning-and-amazon-braket/ <br>

Reading 15: <br>
Parthasarathy, V. B., Zafar, A., Khan, A., & Shahid, A. (2024). The ultimate guide to fine-tuning llms from basics to breakthroughs: An exhaustive review of technologies, research, best practices, applied research challenges and opportunities. arXiv preprint arXiv:2408.13296. <br>

Reading 15: <br>
Federated Learning Books <br>
Book 1: Federated Learning Unlocking the Power of Collaborative Intelligence <br>
Book 2: Federated Learning with Python <br>
Reading 1: https://www.datacamp.com/blog/federated-learning <br>
Paper 1: Zhang, C., Xie, Y., Bai, H., Yu, B., Li, W., & Gao, Y. (2021). A survey on federated learning. Knowledge-Based Systems, 216, 106775. <br>
Paper 2: Shenaj, D., Rizzoli, G., & Zanuttigh, P. (2023). Federated learning in computer vision. IEEE Access. <br>

<br>
Things to follow and read for ML, AI and Maths <br>
1. https://www.iso.org/artificial-intelligence/machine-learning <br>
2. https://dataskeptic.com/ <br>
3. https://twimlai.com/about/ <br>
4. https://blogs.nvidia.com/ai-podcast/ <br>
5. https://soundcloud.com/nlp-highlights <br>
6. https://news.mit.edu/topic/machine-learning <br>
7. https://www.quantamagazine.org/mathematics/ <br>

<br>
GPU Computing <br>
Reading 1: Li, M., Bi, Z., Wang, T., Wen, Y., Niu, Q., Liu, J., ... & Liu, M. (2024). Deep learning and machine learning with gpgpu and cuda: Unlocking the power of parallel computing. arXiv preprint arXiv:2410.05686. <br>

<br>
Liquid Neural Networks <br>
K. Kumar, A. Verma, N. Gupta and A. Yadav, "Liquid Neural Networks: A Novel Approach to Dynamic Information Processing," 2023 International Conference on Advances in Computation, Communication and Information Technology (ICAICCIT), Faridabad, India, 2023, pp. 725-730, doi: 10.1109/ICAICCIT60255.2023.10466162. keywords: {Training;Liquids;Neural networks;Supervised learning;Speech recognition;Reinforcement learning;Reservoirs;Neural Network Architecture;Liquid Layer;Temporal Dependencies;Time-Series Forecasting;Natural Language Processing;Reservoir Dynamics;Training Techniques}, <br>
<br>

Uncertainity Quantification in LLMs <br>
Paper 1: Liu, L., Pan, Y., Li, X., & Chen, G. (2024). Uncertainty Estimation and Quantification for LLMs: A Simple Supervised Approach. arXiv preprint arXiv:2404.15993. <br>

Data Mining <br>
Data Mining with Python: Theory, Application, and Case Studies <br>

AI Roadmap
1. Programming in Python3: A Complete Introduction to the Python Language (Mark Summerfield)
2. Kaganovskiy, L. (2025). Applied Statistics with Python: Volume I: Introductory Statistics and Regression. CRC Press.
3. Introduction To Statistical Learning With Python
4. Pytorch https://www.youtube.com/watch?v=V_xro1bcAuA&pp=ygUScHl0b3JjaCBmdWxsIHZpZGVv
5. Reinforcement Learning - Adaptive Computation and Machine Learning
Sutton, R. S., & Barto, A. G. (1998). Reinforcement learning: An introduction (Vol. 1, No. 1, pp. 9-11). Cambridge: MIT press.
6. Core Foundations - Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition with Language Models
https://web.stanford.edu/~jurafsky/slp3/
7. Python for Natural Language Processing - Pierre M. Nugues
